{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the basic necessities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms = pd.read_csv(\"spam.csv\",encoding='latin-1')\n",
    "sms.columns = ['label', 'message']\n",
    "\n",
    "sms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5572</td>\n",
       "      <td>5572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4825</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                 message\n",
       "count   5572                    5572\n",
       "unique     2                    5169\n",
       "top      ham  Sorry, I'll call later\n",
       "freq    4825                      30"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have `4825` ham and `747` spam messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  label_num\n",
       "0   ham  Go until jurong point, crazy.. Available only ...          0\n",
       "1   ham                      Ok lar... Joking wif u oni...          0\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...          1\n",
       "3   ham  U dun say so early hor... U c already then say...          0\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...          0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms['label_num'] = sms['label'].map({'ham': 0, 'spam': 1})\n",
    "sms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add a basic feature 'message length' to our dataset. You may find many advanced feature engineering techniques for spam classification problem but at the end it all boils down to your domain knowledge and expected accuracy of results. For now, we will add only this feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>label_num</th>\n",
       "      <th>message_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  label_num  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...          0   \n",
       "1   ham                      Ok lar... Joking wif u oni...          0   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...          1   \n",
       "3   ham  U dun say so early hor... U c already then say...          0   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...          0   \n",
       "\n",
       "   message_len  \n",
       "0          111  \n",
       "1           29  \n",
       "2          155  \n",
       "3           49  \n",
       "4           61  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms['message_len'] = sms.message.apply(len)\n",
    "sms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Message Length')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "sms[sms.label=='ham'].message_len.plot(bins=35, kind='hist', color='blue', \n",
    "                                       label='Ham messages', alpha=0.6)\n",
    "sms[sms.label=='spam'].message_len.plot(kind='hist', color='red', \n",
    "                                       label='Spam messages', alpha=0.6)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Message Length\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that spam messages are usually longer than ham messages. Let's check out each category separately to get a numeric view on this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_num</th>\n",
       "      <th>message_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4825.0</td>\n",
       "      <td>4825.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>71.023627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>58.016023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>33.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>52.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>92.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>910.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label_num  message_len\n",
       "count     4825.0  4825.000000\n",
       "mean         0.0    71.023627\n",
       "std          0.0    58.016023\n",
       "min          0.0     2.000000\n",
       "25%          0.0    33.000000\n",
       "50%          0.0    52.000000\n",
       "75%          0.0    92.000000\n",
       "max          0.0   910.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms[sms.label=='ham'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_num</th>\n",
       "      <th>message_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>747.0</td>\n",
       "      <td>747.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>138.866131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>29.183082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>132.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>149.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>157.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "      <td>224.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label_num  message_len\n",
       "count      747.0   747.000000\n",
       "mean         1.0   138.866131\n",
       "std          0.0    29.183082\n",
       "min          1.0    13.000000\n",
       "25%          1.0   132.500000\n",
       "50%          1.0   149.000000\n",
       "75%          1.0   157.000000\n",
       "max          1.0   224.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms[sms.label=='spam'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, 75% of the ham messages have length less than 92 characters whereas 75% of the spam messages have length more than 132 characters. So basically, if you just judge a message by its length, you would be right 75% of the time.\n",
    "**Pretty Interesting, isn't it?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Pre-Processing\n",
    "\n",
    "Before we get into any kind of machine learning classification models, let's clean our messages of `punctuation` and `stopwords`. The former is pretty obvious to everyone, but for those who are not familiar with the latter one, /*stopwords*/ are commonly occuring words found in any launguage text which help form continuity and structure but attribute no particular or unique meaning to the sentence, for e.g. \"The\",\"is\",\"at\", etc. Python's `nltk` library has a list of stopwords that we can use to filter out these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def text_process(message):\n",
    "    \"\"\"\n",
    "    Takes in a string of text and remove punctuation & stopwords\n",
    "    Return type: string\n",
    "    Returns: String of cleaned message\n",
    "    \"\"\"\n",
    "    STOPWORDS = stopwords.words('english') + ['u', 'ü', 'ur', '4', '2', 'im', 'dont', 'doin', 'ure']\n",
    "    # Check characters to see if they are in punctuation\n",
    "    nopunc = [char for char in message if char not in string.punctuation]\n",
    "\n",
    "    # Join the characters again to form the string.\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    # Now just remove any stopwords\n",
    "    return ' '.join([word for word in nopunc.split() if word.lower() not in STOPWORDS])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply the above function and create a new field having clean messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms['clean_message'] = sms['message'].apply(text_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>label_num</th>\n",
       "      <th>message_len</th>\n",
       "      <th>clean_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>Go jurong point crazy Available bugis n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>Ok lar Joking wif oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "      <td>Free entry wkly comp win FA Cup final tkts 21s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>dun say early hor c already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>Nah think goes usf lives around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  label_num  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...          0   \n",
       "1   ham                      Ok lar... Joking wif u oni...          0   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...          1   \n",
       "3   ham  U dun say so early hor... U c already then say...          0   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...          0   \n",
       "\n",
       "   message_len                                      clean_message  \n",
       "0          111  Go jurong point crazy Available bugis n great ...  \n",
       "1           29                              Ok lar Joking wif oni  \n",
       "2          155  Free entry wkly comp win FA Cup final tkts 21s...  \n",
       "3           49                    dun say early hor c already say  \n",
       "4           61             Nah think goes usf lives around though  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at what are the most commonly occuring words in each category of messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words in ham messages are:\n",
      " [('get', 303), ('ltgt', 276), ('ok', 272), ('go', 247), ('ill', 236), ('know', 232), ('got', 231), ('like', 229), ('call', 229), ('come', 224)]\n",
      "\n",
      "Top 10 words in spam messages are:\n",
      " [('call', 347), ('free', 216), ('txt', 150), ('mobile', 123), ('text', 120), ('claim', 113), ('stop', 113), ('reply', 101), ('prize', 92), ('get', 83)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Splitting sentences into tokens\n",
    "ham_tokenized = sms[sms.label=='ham']['clean_message'].apply(lambda x: [word.lower() for word in x.split()])\n",
    "spam_tokenized = sms[sms.label=='spam']['clean_message'].apply(lambda x: [word.lower() for word in x.split()])\n",
    "\n",
    "# Creating counter objects for keeping track of token frequency\n",
    "ham_words = Counter()\n",
    "spam_words = Counter()\n",
    "\n",
    "# Iterating and updating counter for all messages in the category\n",
    "for msg in ham_tokenized:\n",
    "    ham_words.update(msg)\n",
    "for msg in spam_tokenized:\n",
    "    spam_words.update(msg)\n",
    "    \n",
    "print(\"Top 10 words in ham messages are:\\n\",ham_words.most_common(10))\n",
    "print(\"\\nTop 10 words in spam messages are:\\n\",spam_words.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we observe the above results, we can see that there are different forms of the same root word getting repeated, such as \"get\"-\"got\",\"come\"-\"go\". As these hold similar significance in a message from a spam/ham classification perspective, let's just reduce every word to its root word (aka `stem`) using the `Porter Stemmer`. If you need more background on the difference between `lemmatization` and `stemming`, when to use which, and how to implement it, feel free to browse this link from [Datacamp](https://www.datacamp.com/community/tutorials/stemming-lemmatization-python)\n",
    "\n",
    "Let's redefine out `text_process` function incorporating Stemming in there. This time we will also use nltk's `tokenize` function to convert strings into tokens instead of our normal split methodology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "def text_process_stem(message):\n",
    "    \"\"\"\n",
    "    Takes in a string of text and performs the following steps:\n",
    "    1. Remove punctuation\n",
    "    2. Tokenize\n",
    "    3. Remove stopwords\n",
    "    4. Stems words to their root forms\n",
    "    Return type: string\n",
    "    Returns: String of cleaned & stemmed message\n",
    "    \"\"\"\n",
    "    STOPWORDS = stopwords.words('english') + ['u', 'ü', 'ur', '4', '2', 'im', 'dont', 'doin', 'ure']\n",
    "    # Check characters to see if they are in punctuation\n",
    "    nopunc = [char for char in message if char not in string.punctuation]\n",
    "\n",
    "    # Join the characters again to form the string\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    # Instantiating a PorterStemmer object\n",
    "    porter = PorterStemmer()\n",
    "    token_words = word_tokenize(nopunc)\n",
    "    stem_message=[]\n",
    "    for word in token_words:\n",
    "        stem_message.append(porter.stem(word))\n",
    "        stem_message.append(\" \")\n",
    "    return ''.join(stem_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>label_num</th>\n",
       "      <th>message_len</th>\n",
       "      <th>clean_message</th>\n",
       "      <th>clean_message_stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>Go jurong point crazy Available bugis n great ...</td>\n",
       "      <td>Go jurong point crazy Available bugis n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>Ok lar Joking wif oni</td>\n",
       "      <td>Ok lar Joking wif oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "      <td>Free entry wkly comp win FA Cup final tkts 21s...</td>\n",
       "      <td>Free entry wkly comp win FA Cup final tkts 21s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>dun say early hor c already say</td>\n",
       "      <td>dun say early hor c already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>Nah think goes usf lives around though</td>\n",
       "      <td>Nah think goes usf lives around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  label_num  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...          0   \n",
       "1   ham                      Ok lar... Joking wif u oni...          0   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...          1   \n",
       "3   ham  U dun say so early hor... U c already then say...          0   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...          0   \n",
       "\n",
       "   message_len                                      clean_message  \\\n",
       "0          111  Go jurong point crazy Available bugis n great ...   \n",
       "1           29                              Ok lar Joking wif oni   \n",
       "2          155  Free entry wkly comp win FA Cup final tkts 21s...   \n",
       "3           49                    dun say early hor c already say   \n",
       "4           61             Nah think goes usf lives around though   \n",
       "\n",
       "                                  clean_message_stem  \n",
       "0  Go jurong point crazy Available bugis n great ...  \n",
       "1                              Ok lar Joking wif oni  \n",
       "2  Free entry wkly comp win FA Cup final tkts 21s...  \n",
       "3                    dun say early hor c already say  \n",
       "4             Nah think goes usf lives around though  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms['clean_message_stem'] = sms['message'].apply(text_process)\n",
    "sms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Build & Testing\n",
    "\n",
    "The classification alogrithms we would be using for our problem usually work with numerical feature vector. For that reason, we will need to convert our messages into numerical features. There are multiple methods to convert a corpus of text into a numerical vector, simplest of which is `bag-of-words` approach, where each sentence is expressed using a bag of words that we call `vocabulary` and every word occurs a number of times in that sentence. For performing this conversion, we will use the `CountVectorizer` available in scikit-learn.\n",
    "\n",
    "To perform this modelling, we will be subjecting our data to three sequential steps:\n",
    "1. **Bag-of-Words creation**: We will use the `CountVectorizer` to create word-message matrix with each element representing the freuquency of occurence for that word-message combination. You can imagine it to look like the following table:\n",
    "\n",
    "| Word/Message | Message 1 | Message 2 | ... | Message N |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| Word 1 | 0 | 1 | ... | 1 |\n",
    "| Word 2 | 2 | 0 | ... | 0 |\n",
    "| Word 3 | 1 | 1 | ... | 1 |\n",
    "\n",
    "2. **Transforming using TF-IDF***: TF-IDF stands for \"Term Frequency - Inverse Document Frequency\", what it does is it positively weighs every term for its occurence in a message and also negatively weighs that term for occuring frequently in general, which results into a normalized weight associated to every token. Taking from the [official documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html#sklearn.feature_extraction.text.TfidfTransformer)\n",
    "> The goal of using tf-idf instead of the raw frequencies of occurrence of a token in a given document is to scale down the impact of tokens that occur very frequently in a given corpus and that are hence empirically less informative than features that occur in a small fraction of the training corpus\n",
    "\n",
    "3. **Multinomial Naive Bayes Model**: Using the normalized weightages for each word in the corpus as input, we then fit a Naive Bayes classifier model to this data. Naive Bayes works great in spam filtering use case because it assumes that every feature (token in our case) is independently related to the overall outcome. Quoting the official documentation:\n",
    "> The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as tf-idf may also work.\n",
    "\n",
    "Lastly, to evaluate the efficacy of our model we will be using the precision score. The reason for choosing precision is that it penalizes the model for false positives, i.e. in our case classifying a normal/important message as Spam and putting it in Junk. To get a good idea about the different evaluation metrics and when to use them, you can refer to this [article](https://towardsdatascience.com/top-10-model-evaluation-metrics-for-classification-ml-models-a0a0f1d51b9)\n",
    "\n",
    "Let's split the dataset into train and test sets, followed by creating a machine-learning pipeline comprising the above three steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('bow', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_...ear_tf=False, use_idf=True)), ('model', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "\n",
    "X = sms.clean_message\n",
    "y = sms.label_num\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "pipe = Pipeline([('bow', CountVectorizer()), \n",
    "                 ('tfid', TfidfTransformer()),  \n",
    "                 ('model', MultinomialNB())])\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 0.966978\n",
      "Precision is: 1.000000\n",
      "ROC-AUC is: 0.872222\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "# Evaluating model\n",
    "print(\"Accuracy is: {:2f}\".format(metrics.accuracy_score(y_test,y_pred)))\n",
    "print(\"Precision is: {:2f}\".format(metrics.precision_score(y_test,y_pred)))\n",
    "print(\"ROC-AUC is: {:2f}\".format(metrics.roc_auc_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a good precision but not so good AUC score. Let's try comparing this with logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 0.963388\n",
      "Precision is: 0.977778\n",
      "ROC-AUC is: 0.865430\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipe_log = Pipeline([('bow', CountVectorizer()), \n",
    "                 ('tfid', TfidfTransformer()),  \n",
    "                 ('logmodel', LogisticRegression(solver='liblinear'))])\n",
    "                     \n",
    "pipe_log.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe_log.predict(X_test)\n",
    "\n",
    "# Evaluating model\n",
    "print(\"Accuracy is: {:2f}\".format(metrics.accuracy_score(y_test,y_pred)))\n",
    "print(\"Precision is: {:2f}\".format(metrics.precision_score(y_test,y_pred)))\n",
    "print(\"ROC-AUC is: {:2f}\".format(metrics.roc_auc_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# As we see, logistic regression is coming out to be a better model here rather than Naive-Bayes. We could further tune the count vectorizer we are using or the stemming/lemmatization techniques to increase the efficacy of this model. But for now, let's just use this model and build a web app based on it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
